{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jojo\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Jojo\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from graphviz import Source\n",
    "from sklearn import svm, metrics, grid_search, tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import normalized deltas for training and testing data\n",
    "# for the sake of reproducibility, the training data contains the 2015 and 2016 seasons, and testing contains the 2017 season\n",
    "# No random selection of training and testing data is used here\n",
    "\n",
    "training = DataFrame.from_csv(\"/Users/Jojo/week-one-cfb-predictions/data/raw_data_normalized_t.csv\")\n",
    "testing = DataFrame.from_csv(\"/Users/Jojo/week-one-cfb-predictions/data/raw_data_normalized_test.csv\")\n",
    "training = training.dropna(axis=1, how='all')\n",
    "testing = testing.dropna(axis=1, how='all')\n",
    "training = training.dropna(axis=0, how='any')\n",
    "testing = testing.dropna(axis=0, how='any')\n",
    "trainLabel = training['Label']\n",
    "testLabel = testing['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now drop the unwanted data, which includes team names and labels\n",
    "# Games will be classified as a win or loss for the 'Home' team, indicated by a 1 or 0, respectively\n",
    "\n",
    "training = training.drop('away_team', 1).drop('home_team', 1).drop(\"Label\", 1)\n",
    "testing = testing.drop('away_team', 1).drop('home_team', 1).drop(\"Label\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Although this is overwritten by the model, this classifier shows how the importance of each feature is weighted in the context of feature elimination\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(training.as_matrix(), trainLabel.as_matrix())\n",
    "#print(sorted(model.feature_importances_))\n",
    "\n",
    "# To view the calculated importances of the features based on accuracy, uncomment the print statement above. \n",
    "# Note that some of the imporances are 0.0, meaning that they are of no use to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we reassign the model and apply the RFE package with 17 features\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "rfe = RFE(model, 17)\n",
    "fit = rfe.fit(training.as_matrix(), trainLabel.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have our desired features, so now need to rebuild the training and testing sets\n",
    "# This means that we have to iterate through the rankings from the previous step to create new DataFrames\n",
    "\n",
    "dummy = DataFrame()\n",
    "dtest = DataFrame()\n",
    "\n",
    "for i in range(len(fit.ranking_)):\n",
    "    if fit.ranking_[i] == 1:\n",
    "        #print(list(training.columns)[i], fit.support_[i])\n",
    "        dummy[list(training.columns)[i]] = training[list(training.columns)[i]]\n",
    "        dtest[list(testing.columns)[i]] = testing[list(testing.columns)[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[11 12]\n",
      " [ 2 49]]\n",
      "Accuracy: 0.810810810811\n",
      "F1 Score: 0.875\n",
      "Precision: 0.803278688525\n",
      "Recall: 0.960784313725\n"
     ]
    }
   ],
   "source": [
    "model.fit( dummy.as_matrix(), trainLabel.as_matrix())\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix( np.array(testLabel), model.predict( dtest.as_matrix() )))\n",
    "print(\"Accuracy:\", metrics.accuracy_score( np.array(testLabel), model.predict( dtest.as_matrix() )))\n",
    "print(\"F1 Score:\", metrics.f1_score( np.array(testLabel), model.predict( dtest.as_matrix() )))\n",
    "print(\"Precision:\", metrics.precision_score( np.array(testLabel), model.predict( dtest.as_matrix() )))\n",
    "print(\"Recall:\", metrics.recall_score( np.array(testLabel), model.predict( dtest.as_matrix() )))\n",
    "\n",
    "# These are the metrics for the ExtraTrees classifier, as modeled above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[10 13]\n",
      " [ 2 49]]\n",
      "Accuracy: 0.797297297297\n",
      "F1 Score: 0.867256637168\n",
      "Precision: 0.790322580645\n",
      "Recall: 0.960784313725\n"
     ]
    }
   ],
   "source": [
    "# Note that, by the nature of the ExtraTrees Classifier, the results of each test will vary from the others\n",
    "# Now, we test this same dataset with an rbf-based SVM classifier to view the results.\n",
    "# grid_seachCV is used for C and gamma value selection.\n",
    "\n",
    "model = machine = grid_search.GridSearchCV( svm.SVC( kernel='rbf', degree=3 ), cv=2, param_grid = {\"C\": [ 4, 2, 1, 0.1, 0.01, 0.001], \"gamma\": np.logspace(-2, 2, 5)})\n",
    "model.fit( dummy.as_matrix(), trainLabel.as_matrix())\n",
    "    \n",
    "#print(\"Prediction:\", model.predict( dtest.as_matrix() ).round())\n",
    "#print(\"Real Value:\", np.array(testLabel))\n",
    "    \n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix( np.array(testLabel), model.predict( dtest.as_matrix() ).round()))\n",
    "print(\"Accuracy:\", metrics.accuracy_score( np.array(testLabel), model.predict( dtest.as_matrix() ).round()))\n",
    "print(\"F1 Score:\", metrics.f1_score( np.array(testLabel), model.predict( dtest.as_matrix() ).round()))\n",
    "print(\"Precision:\", metrics.precision_score( np.array(testLabel), model.predict( dtest.as_matrix() ).round()))\n",
    "print(\"Recall:\", metrics.recall_score( np.array(testLabel), model.predict( dtest.as_matrix() ).round()))\n",
    "\n",
    "# Note: we need to round the prediction results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_ Opponent_Fumble_Recovery_Percentage 8\n",
      "d_ 2nd_Half_Points/Game 62\n",
      "d_ Opponent_2nd_Half_Points/Game 9\n",
      "d_ Yards_per_Game 43\n",
      "d_ Fourth_Downs_per_Game 12\n",
      "d_ Punt_Attempts_per_Game 25\n",
      "d_ 1st_Quarter_Points/Game 15\n",
      "d_ Offensive_Points_per_Game_(Estimated) 76\n",
      "d_ Yards_per_Point 31\n",
      "d_ Points_per_Play 69\n",
      "d_ 1st_Half_Points/Game 32\n",
      "d_ Opponent_Average_Scoring_Margin 46\n",
      "d_ Opponent_Penalty_Yards_per_Game 7\n",
      "d_ Yards_per_Play 13\n",
      "d_RecPoints 63\n",
      "d_OffPassSP 66\n",
      "d_OffSDSP 30\n",
      "d_ Opponent_Offensive_Touchdowns_per_Game 6\n",
      "d_ Third_Down_Conversions_per_Game 7\n",
      "d_ 4th_Quarter_Time_of_Possession_Share_% 22\n",
      "d_ Opponent_Red_Zone_Scoring_Percentage_(TDs_and_FGs) 26\n",
      "d_ Offensive_Touchdowns_per_Game 19\n",
      "d_ 3rd_Quarter_Points/Game 37\n",
      "d_ Average_Scoring_Margin 48\n",
      "d_ Punts_per_Play 48\n",
      "d_RecRank 51\n",
      "d_OffSP 40\n",
      "d_OffRushSP 16\n",
      "d_ Fourth_Down_Conversions_per_Game 21\n",
      "d_ Opp_Yards_per_Point 17\n",
      "d_ Opponent_Third_Down_Conversion_Percentage 47\n",
      "d_ Yards_per_Completion 50\n",
      "d_ Opponent_Punts_per_Offensive_Score 9\n",
      "d_ Punts_per_Offensive_Score 51\n",
      "d_ Yards_per_Point_Margin 45\n",
      "d_SPMargin 36\n",
      "d_SPRank 32\n",
      "d_OffSuccRate 23\n",
      "d_ Yards_per_Pass_Attempt 34\n",
      "d_ Opponent_Turnover_Margin_per_Game 9\n",
      "d_ Opponent_Red_Zone_Scoring_Attempts_per_Game 27\n",
      "d_ Pass_Attempts_per_Game 6\n",
      "d_ Turnover_Margin_per_Game 8\n",
      "d_ Opponent_Points_per_Play 7\n",
      "d_ Gross_Punt_Yards_per_Game 25\n",
      "d_ Opponent_Giveaway_Fumble_Recovery_Percentage 12\n",
      "d_ Opponent_Punts_per_Play 5\n",
      "d_ Opponent_Rushing_Yards_per_Game 9\n",
      "d_OffPDSP 13\n",
      "d_ Points_per_Game 5\n",
      "d_ Opp_3rd_Quarter_Points/Game 24\n",
      "d_ Passing_Yards_Percentage 2\n",
      "d_ Opponent_Field_Goals_Made_per_Game 8\n",
      "d_ Opponent_Rushing_Yards_Percentage 11\n",
      "d_ Plays_per_Game 2\n",
      "d_ Opponent_Third_Down_Conversions_per_Game 12\n",
      "d_ Rushing_Play_Percentage_ 4\n",
      "d_ Opponent_Fumbles_Lost_per_Game 8\n",
      "d_ Opponent_Points_per_Game 11\n",
      "d_ Opponent_Gross_Punt_Yards_per_Game 11\n",
      "d_ Opponent_Yards_per_Rush_Attempt 4\n",
      "d_ Field_Goal_Attempts_per_Game 16\n",
      "d_ Opponent_Rushing_First_Downs_per_Game 4\n",
      "d_ 4th_Quarter_Points/Game 7\n",
      "d_ Opponent_Passing_Play_Percentage 4\n",
      "d_ Takeaway_Fumble_Recovery_Percentage 4\n",
      "d_ Interceptions_Thrown_Percentage 6\n",
      "d_OffIsoPPP 10\n",
      "d_ Opponent_Penalties_per_Game 1\n",
      "d_ Red_Zone_Scoring_Attempts_per_Game 13\n",
      "d_ Opponent_Offensive_Points_per_Game_(Estimated) 8\n",
      "d_ Points_per_Play_Margin 5\n",
      "d_ Opponent_Points_per_Field_Goal_Attempt 7\n",
      "d_ Fumble_Recovery_Percentage 4\n",
      "d_ Rushing_Attempts_per_Game 11\n",
      "d_ Interceptions_per_Game 4\n",
      "d_ 2nd_Quarter_Points/Game 3\n",
      "d_ Fumbles_Not_Lost_per_Game 2\n",
      "d_ Completions_per_Game 6\n",
      "d_ Opp_4th_Quarter_Points/Game 2\n",
      "d_ Fourth_Down_Conversion_Percentage 1\n",
      "d_ QB_Sacked_Percentage 6\n",
      "d_ Third_Downs_per_Game 5\n",
      "d_ Opponent_Penalties_per_Play 7\n",
      "d_ Average_Team_Passer_Rating 4\n",
      "d_ Opponent_Yards_per_Play 1\n",
      "d_ Opponent_Red_Zone_Scores_per_Game_(TDs_and_FGs) 3\n",
      "d_ 1st_Quarter_Time_of_Possession_Share_% 3\n",
      "d_ Completion_Percentage 3\n",
      "d_ Takeaways_per_Game 2\n",
      "d_ Penalty_Yards_per_Penalty 1\n",
      "d_ Fumbles_per_Game 3\n",
      "d_ Passing_Play_Percentage 2\n",
      "d_ Opponent_Rushing_Play_Percentage_ 2\n",
      "d_ Opponent_Rushing_Attempts_per_Game 1\n",
      "d_ 2nd_Half_Time_of_Possession_Share_% 1\n",
      "d_ Red_Zone_Scoring_Percentage_(TDs_and_FGs) 3\n",
      "d_ Time_of_Possession_Percentage_(Net_of_OT) 1\n",
      "d_ Opponent_Field_Goal_Attempts_per_Game 3\n",
      "d_ Opponent_1st_Half_Points/Game 1\n",
      "d_ Opponent_Third_Downs_per_Game 1\n",
      "d_ Opponent_Pass_Attempts_per_Game 2\n",
      "d_ Average_Time_of_Possession_(Excluding_OT) 1\n",
      "d_ Incompletions_per_Game 2\n",
      "d_2OW 1\n",
      "d_ Opponent_Passing_Yards_Percentage 3\n",
      "d_ Opponent_Fumbles_per_Game 3\n",
      "d_ Opponent_Plays_per_Game 1\n",
      "d_ Rushing_Yards_Percentage 1\n"
     ]
    }
   ],
   "source": [
    "# Since the features are carried over from the ExtraTrees Classifier, there is still random selection affecting these values\n",
    "# As a result, running this code through a loop allows us to find which features RFE tends to favor\n",
    "# To test this, run this with k=100 iterations\n",
    "\n",
    "freqs = dict()\n",
    "\n",
    "for k in range(100):\n",
    "    model = ExtraTreesClassifier()\n",
    "    rfe = RFE(model, 17)\n",
    "    fit = rfe.fit(training.as_matrix(), trainLabel.as_matrix())\n",
    "    \n",
    "    dummy = DataFrame()\n",
    "    dtest = DataFrame()\n",
    "    \n",
    "    for i in range(len(fit.ranking_)):\n",
    "        if fit.ranking_[i] == 1:\n",
    "            #print(list(training.columns)[i], fit.support_[i])\n",
    "            dummy[list(training.columns)[i]] = training[list(training.columns)[i]]\n",
    "            dtest[list(testing.columns)[i]] = testing[list(testing.columns)[i]]\n",
    "            try:\n",
    "                freqs[list(training.columns)[i]] += 1\n",
    "            except KeyError:\n",
    "                freqs[list(training.columns)[i]] = 1\n",
    "\n",
    "\n",
    "import operator\n",
    "for i in sorted(freqs, key=operator.itemgetter(1), reverse=True):\n",
    "    print (i, freqs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
